{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from collections import defaultdict\n",
    "from pandas import DataFrame\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model \n",
    "model_path = '/Users/chenjialu/Desktop/DL_Assignment2/Code_AWS/vgg16_fn4/'\n",
    "model = load_model(model_path+'vgg16_fn4_model.h5')\n",
    "# specify the image shape\n",
    "image_shape = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': '0',\n",
       " '1': '1',\n",
       " '10': '18',\n",
       " '11': '19',\n",
       " '12': '2',\n",
       " '13': '20',\n",
       " '14': '21',\n",
       " '15': '22',\n",
       " '16': '23',\n",
       " '17': '24',\n",
       " '18': '25',\n",
       " '19': '26',\n",
       " '2': '10',\n",
       " '20': '27',\n",
       " '21': '28',\n",
       " '22': '29',\n",
       " '23': '3',\n",
       " '24': '30',\n",
       " '25': '31',\n",
       " '26': '32',\n",
       " '27': '33',\n",
       " '28': '34',\n",
       " '29': '35',\n",
       " '3': '11',\n",
       " '30': '36',\n",
       " '31': '37',\n",
       " '32': '38',\n",
       " '33': '39',\n",
       " '34': '4',\n",
       " '35': '40',\n",
       " '36': '41',\n",
       " '37': '42',\n",
       " '38': '43',\n",
       " '39': '44',\n",
       " '4': '12',\n",
       " '40': '45',\n",
       " '41': '46',\n",
       " '42': '47',\n",
       " '43': '48',\n",
       " '44': '49',\n",
       " '45': '5',\n",
       " '46': '50',\n",
       " '47': '51',\n",
       " '48': '52',\n",
       " '49': '53',\n",
       " '5': '13',\n",
       " '50': '54',\n",
       " '51': '55',\n",
       " '52': '56',\n",
       " '53': '57',\n",
       " '54': '58',\n",
       " '55': '59',\n",
       " '56': '6',\n",
       " '57': '60',\n",
       " '58': '61',\n",
       " '59': '7',\n",
       " '6': '14',\n",
       " '60': '8',\n",
       " '61': '9',\n",
       " '7': '15',\n",
       " '8': '16',\n",
       " '9': '17'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the mapping from prediction to actual label\n",
    "with open(model_path+'label_map.json') as f:\n",
    "    label_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the folder of the test-set \n",
    "data_dir = '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/vali-set/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give the prediction of one image with the image file name\n",
    "def predict_image(filename, model):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    img_path = data_dir + filename \n",
    "    img = load_img(img_path, target_size=image_shape)  # this is a PIL image\n",
    "    img = img_to_array(img)\n",
    "    img = img/255\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    pred = model.predict(img)\n",
    "    pred = label_map[str(pred.argmax(axis=-1)[0])]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_prediction(output_path, data_dir, model):\n",
    "    \"\"\"\n",
    "    A function to write the predicted classes of images from an image folder to a txt file  \n",
    "    \"\"\"\n",
    "    with open(output_path, 'w') as f:\n",
    "        # for each file in the \n",
    "        for filename in os.listdir(data_dir):\n",
    "            pred = predict_image(filename, model)\n",
    "            f.write(filename+' '+pred+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_prediction('/Users/chenjialu/Desktop/test.txt', data_dir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('label_map.json', 'w') as fp:\n",
    "    json.dump(label_map, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/0': 0,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/1': 1,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/10': 2,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/11': 3,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/12': 4,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/13': 5,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/14': 6,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/15': 7,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/16': 8,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/17': 9,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/18': 10,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/19': 11,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/2': 12,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/20': 13,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/21': 14,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/22': 15,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/23': 16,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/24': 17,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/25': 18,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/26': 19,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/27': 20,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/28': 21,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/29': 22,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/3': 23,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/30': 24,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/31': 25,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/32': 26,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/33': 27,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/34': 28,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/35': 29,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/36': 30,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/37': 31,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/38': 32,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/39': 33,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/4': 34,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/40': 35,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/41': 36,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/42': 37,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/43': 38,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/44': 39,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/45': 40,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/46': 41,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/47': 42,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/48': 43,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/49': 44,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/5': 45,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/50': 46,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/51': 47,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/52': 48,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/53': 49,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/54': 50,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/55': 51,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/56': 52,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/57': 53,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/58': 54,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/59': 55,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/6': 56,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/60': 57,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/61': 58,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/7': 59,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/8': 60,\n",
       " '/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/9': 61}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check mapping directly \n",
    "from glob import glob\n",
    "class_names = glob(\"/Users/chenjialu/Desktop/DL_Assignment2/Assignment-2-Dataset-Round-1/data/train/*\") # Reads all the folders in which images are present\n",
    "class_names = sorted(class_names) # Sorting them\n",
    "name_id_map = dict(zip(class_names, range(len(class_names))))\n",
    "name_id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Rest = keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.topology.InputLayer object at 0x1c25e5b320>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x1c25e5b5c0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x1c25e5b438>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x1c25e5bc18>\n",
      "<keras.layers.core.Activation object at 0x1c25e5bcc0>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x1c1852eac8>\n"
     ]
    }
   ],
   "source": [
    "for layer in model_Rest.layers[:6]:\n",
    "    print(layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
